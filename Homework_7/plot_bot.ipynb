{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib for jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dependencies\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import tweepy\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Tweepy Auth with JSON parser\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables necessary for 5-min check, target term history, filtering tweets that are not in english;\n",
    "x = 0\n",
    "tweet_id_1 = None\n",
    "tweet_id_2 = None\n",
    "target_term = \"\"\n",
    "requesting_user = \"\"\n",
    "target_term_history = []\n",
    "tweet_list = []\n",
    "oldest_tweet = None\n",
    "b = 1\n",
    "lang = \"en\"\n",
    "# For every 5 minutes, get the most recent one\n",
    "while(b):\n",
    "    while(True):\n",
    "        if x == 1:\n",
    "            x = 0\n",
    "            try:\n",
    "                # Scan for mention to analyze and use since_id to get the latest mention\n",
    "                response = api.mentions_timeline(since_id=tweet_id_1, count=1)\n",
    "                # Update the value with every new mention grabbed\n",
    "                tweet_id_1 = response[0][\"id\"]\n",
    "                # Grab target term\n",
    "                target_term = response[0][\"text\"].split(\"@\")[2]\n",
    "                requesting_user = response[0][\"user\"][\"screen_name\"]\n",
    "                # Make it so that if a term has already been searched once,\n",
    "                # it won't get searched again\n",
    "                if target_term not in target_term_history:\n",
    "                    target_term_history.append(target_term)\n",
    "                    # Grab the tweets, 100 for each of 5 pages\n",
    "                    for x in range(5):\n",
    "                        public_tweets = api.user_timeline(target_term, \n",
    "                                                          count=100, \n",
    "                                                          result_type=\"recent\",\n",
    "                                                          max_id=oldest_tweet)\n",
    "                        # For each item within my first page of tweets...\n",
    "                        for i in range(len(public_tweets)):\n",
    "                            # Filter tweets that are not in English (due to limitations on VADER)\n",
    "                            if public_tweets[i][\"lang\"] == \"en\":\n",
    "                                # Append the text to my list\n",
    "                                tweet_list.append(public_tweets[i][\"text\"])\n",
    "                                # Store the ID of the latest tweet\n",
    "                                tweet_id_2 = public_tweets[i][\"id\"]\n",
    "                                # Subtract the ID by 1 to get the max_id for the next page\n",
    "                                oldest_tweet = tweet_id_2 - 1\n",
    "                        # Don't want to overload servers\n",
    "                        time.sleep(1)\n",
    "                # Perform sentimental analysis on the tweets\n",
    "                compound_list = []\n",
    "                for text in tweet_list:\n",
    "                    results = analyzer.polarity_scores(text)\n",
    "                    compound_list.append(results[\"compound\"])\n",
    "                # Plot the analysis\n",
    "                numb_of_tweets_X = len(compound_list)\n",
    "                current_date = datetime.today().strftime(\"%m/%d/%Y\")\n",
    "                plt.plot(range(numb_of_tweets_X), compound_list, c=\"#A61515\", marker=\"o\", linewidth=.5)\n",
    "                plt.grid(alpha=1)\n",
    "                plt.title(f\"Sentimental Analysis of Tweets ({current_date})\")\n",
    "                plt.xlabel(\"Tweets Ago\")\n",
    "                plt.ylabel(\"Tweet Polarity\")\n",
    "                plt.legend([f\"@{target_term}\"], loc=\"upper center\", title=\"Tweets\", bbox_to_anchor=(1.28, 1))\n",
    "                plt.savefig(f\"sentimental_analysis_{target_term}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "                # Push the .png to Twitter and post the analysis\n",
    "                api.update_with_media(f\"sentimental_analysis_{target_term}.png\",\n",
    "                                      f\"Here is your analysis of @{target_term}, {requesting_user}!\")\n",
    "                time.sleep(300)\n",
    "                x = 1\n",
    "            # If the target term is in the target history, then this exception will fire\n",
    "            except:\n",
    "                print(\"Empty list: Most recent tweet is already analyzed.\")\n",
    "                print(\"Five minutes until next check for most recent tweet.\")\n",
    "                b = 0\n",
    "                time.sleep(300)\n",
    "                b = 1\n",
    "        else: x += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
